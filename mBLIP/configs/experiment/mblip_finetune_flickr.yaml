# @package _global_
defaults:
  - /evaluation/mblip_eval_captioning@module.evaluation
  - override /trainer: default.yaml # choose trainer from 'configs/trainer/'
#  - override /module: mblip # not used by us but can be set to a file in configs/modules/
  - override /datamodule: mblip_flickr
  - override /callbacks: null
  - override /config_callbacks: trident.yaml
  - override /logger: wandb #csv #wandb.yaml

seed: 42
train: True
test_after_training: False

data_prefix: /media/gregor/DATA/projects/wuerzburg 
train_image_root: ${data_prefix}/mblip/data/pretrain/images 
train_data: ${data_prefix}/mblip/data
xm3600_image_root: ${data_prefix}/iglue/datasets/Crossmodal3600/images
flickr_image_root: ${data_prefix}/iglue/datasets/flickr30k/flickr_images
gqa_image_root: ${data_prefix}/iglue/datasets/gqa/images

blip_checkpoint: ${data_prefix}/mblip/checkpoints/blip2-flant5xl-nolm.bin
blip_model: Salesforce/blip2-flan-t5-xl
llm:  bigscience/mt0-xl #google/flan-t5-xl #bigscience/mt0-xl #bigscience/bloomz-7b1-mt
tokenizer_name: ${llm}

trainer:
  num_sanity_val_steps: 0
  max_epochs: 10
  devices: 1
  precision: 16
  gradient_clip_val: 1.0
  accumulate_grad_batches: 8
  log_every_n_steps: 10
  val_check_interval: 1.0
#  strategy: deepspeed_stage_2
#  limit_train_batches: 5
#  limit_val_batches: 10


datamodule:
  dataloader_cfg:
    train:
      batch_size: 16
      num_workers: 2
    val:
      batch_size: 8
      num_workers: 2
    test:
      batch_size: 8
      num_workers: 2

module:
  evaluation:
    metrics_cfg:
        caption_metrics:
          metric:
            annotation_file: "${train_data}/flickr/flickr_{}_coco_test.json"
  model:
    _target_: src.modules.modeling.mblip.mBLIPModule 
    blip_pretrained: ${blip_model}
    blip_pretrained_checkpoint: ${blip_checkpoint}
    lm_pretrained: /example/path/to/checkpoints/mt0-xl/05_18_2023_16_31_57-0-20595 #${llm}
    train_checkpoint: /example/path/to/checkpoints/05_18_2023_16_31_57/checkpoints/0-20595.ckpt
    #/example/path/to/runs/2023-05-16/16-56-30/checkpoints/0-8016.ckpt
#    lora_checkpoint: /example/path/to/checkpoints/05_18_2023_16_31_57/checkpoints/0-14416/adapter_model.bin
    load_8bit: True
    freeze_vit: True
    freeze_lm: True
    freeze_qformer: False
    freeze_projection: False
    gradient_checkpoint: True
    use_lora: lora_all
    lora_bias: none
    lora_alpha: 16
    lora_r: 8
    lora_dropout: 0.05
  optimizer:
    lr: 0.00003  #0.0005
    weight_decay: 0.1
  scheduler:
    _target_: transformers.optimization.get_cosine_schedule_with_warmup
    num_warmup_steps: 1000

logger:
  csv:
    save_dir: ${hydra:runtime.output_dir}
  wandb:
    name: "finetune=flickr_${hydra:runtime.output_dir}"
    project: "mblip"


callbacks:
  model_checkpoint_on_epoch:
    _target_: src.tasks.vllm.checkpoint.mBLIPModelCheckpoint #lightning.pytorch.callbacks.ModelCheckpoint 
    freeze_vit: ${module.model.freeze_vit}
    freeze_qformer: ${module.model.freeze_qformer}
    freeze_lm: ${module.model.freeze_lm}
    freeze_projection: ${module.model.freeze_projection}
    lora: True
#    monitor: "" # name of the logged metric which determines when model is improving
    every_n_epochs: 1
    verbose: false
    save_top_k: -1 # -1 -> all models are saved
    save_last: false # additionaly always save model from last epoch
    dirpath: "${hydra:runtime.output_dir}/checkpoints/"
    auto_insert_metric_name: false
